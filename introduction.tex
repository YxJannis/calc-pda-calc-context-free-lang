\section{Introduction}
\label{1.0}
\subsection{Roadmap}
\label{1.1}
We will begin by covering the foundations of this research topic by explaining some fundamental prerequisites as well as going over the motivation that led to this research. After this, we will be introducing two exemplary formats which tie our mostly theoretically based research to the real world. Chapter two revisits Calc-regular languages explaining them briefly. These findings by Grosch, Koenig, Lucks \cite{Calc-regular-paper} represent a starting point for our own research, as we will be benefiting greatly from these already established results related to our topic. In the following chapter, a new language class 'Calc-LL(1)' is introduced by us and defined informally by also revisiting LL(1) parsing techniques and referring to some basic work done in an earlier project by the author of this thesis. The most significant results of the research highlighted in this thesis get presented in chapter four by showcasing the concept of an automaton for Calc-LL(1) languages, a 'Calc-PDA'. The structure of such an automaton is explained and two example machines are shown that are based on the two representative formats that were already introduced in chapter one: netstrings and Google's protocol buffers. Following this is a clear breakdown of the formal definition of Calc-PDAs. In the subsequent chapter, a proposition for Calc-LL(1) grammars is made, establishing 'Calc-EBNFs' based on the extended Backus-Naur form for our example formats.
Finally, a summarization will be given as well as the important lookout to future projects that can build upon this thesis' results and findings.\\\\
To fully grasp the research presented in this thesis, some basic knowledge about concepts from formal language theory, automatons and their usage in parsing as well as data serialization is recommended. Fundamental skills in formal language theory and formal automatons for regular and context-free languages\footnote{As per Chomsky hierarchy \cite{Chomsky-Hierarchy}.} are presupposed and not covered. In the first chapter, though, we will be establishing the core foundations of this thesis by also briefly explaining what data serialization means and how our research affects certain areas of this procedure.

\subsection{Length-Prefix Notation in Binary Data Serialization}
\label{1.2}
Computers that communicate with each other can only do so by using the binary system. Let's suppose some party $A$ wants to send a package of messages encoded in UTF-8 to $B$. First of all, $A$ has to convert these messages to its binary representation (serialization), then they can distribute these messages to $B$, who deserializes them to get their original form.
The very basic concept on which the motivation for this thesis is based on revolves around data serialization. Particularly, we will be looking at binary data and its structural representation after being serialized, or vice versa, prior to being deserialized.
Since binary data evidently only relies on two characters, \texttt{0} and \texttt{1}, there exist no symbols that can act as delimiters or punctuation marks in any binary data stream. This fact makes it very challenging for any receiver of data including multiple messages to determine where each of these messages end and/or another one starts. In order to deal with this issue, several binary notations have been established. We will be looking at one of these formats called 'length-prefix notation'. \\\\
Length-prefix notation solves the aforementioned problem by inserting a length field at the beginning of each message, before the actual content. This length field guarantees that any machine which parses a binary data stream for deserialization can identify the length of a current message in the data stream. This also means that given the length of the upcoming serialized message, the parser can calculate at which byte in a data stream this message ends and therefore also where the next one begins. This concept is employed in various known and lesser known data formats, such as 'Google protocol buffers' \cite{google-protobuf-overview}, 'Abstract Syntax Notation One (ASN.1)' \cite{ASN.1}, Portable Network Graphics (PNG) \cite{PNG}, the binary representation of JSON, 'BSON'\cite{BSON-overview}, 'netstrings' \cite{netstrings} and many others.

\subsection{Vulnerabilities in Length-Prefix Languages}
\label{1.3}
Incorrect parsing of length-prefix languages can lead to severe security faults, as seen with the famous 'Heartbleed' exploit. 
This serious bug in the \textit{OpenSSL} cryptographic software library surfaced in 2014 \cite{heartbleed-wiki}. The security vulnerability was the result of a flawed implementation of the so called 'heartbeat' functionality in the library which was added 2 years earlier, in 2012.\\ 
To test if another party $Y$ was still alive, a party $X$ sends a 'heartbeat' package to $Y$ using the binary interface ASN.1 \cite{ASN.1}. This package's structure includes a length-prefix $\ell$ which corresponds to the size of the payload $M_x$. To signal that they are still alive, $Y$ then responds with a similarly formed package including $\ell$ and $M_y=M_x$. Crucially, $Y$ must detect and ignore incorrectly formed packages, $e.g.$, when the size of $M_x$ is bigger than $\ell$ indicated.
\\\\However, $Y$ failed to verify if the length $\ell$ of the length-prefix actually corresponds to the size of the payload $M_x$.
An attacker could therefore send short 'heartbeat' packages to $Y$ with $\ell$ being a significantly larger number than the size of $M_x$. $Y$ does not detect this malformed package and responds with the package expecting the message to be of size $\ell$. As $|M_x| << \ell$, party $Y$ now fills the rest of the message $M_y$ with bytes from the internal storage until $|M_y| = \ell$ is reached. This compromises $\ell-|M_y|$ bytes of $Y$'s internal memory \cite{Heartbeat-info}\cite{heartbleed-site}. \\\\
Heartbleed is the most prominent example on why a fundamental and formally correct definition for length-prefix languages is necessary. Using these foundations, many errors and security concerns can be avoided, especially also when considering cross-format communication.

\subsection{Netstrings}
\label{1.4}
To efficiently work with length-prefix languages and grasp their challenges, many formats lend themselves to be used as working examples. Throughout this thesis, two formats will appear repeatedly, 'netstrings' and 'Google protocol buffers' \cite{google-protobuf-overview}.\\\\
Netstrings \cite{netstrings} represent a simple encoding of self-delimiting strings using length-prefix notation. Every netstring message is built sequentially as follows:
\begin{itemize}
    \item a length-prefix $\ell$ in decimal representation,
    \item a colon (":"), separating the length-prefix from the content,
    \item the content, an arbitrary string consisting of $\ell$ bytes,
    \item a comma (","), marking the end of the netstring structure.
\end{itemize}
The string \texttt{"Hello World"}, including the space between the two words, gets encoded to "\texttt{11:Hello World,}", including the comma after "\texttt{World}". Netstrings allow recursive usage, also called nesting. This means that one netstring can act as a container for another netstring. $E.g.$, both strings "\texttt{Hello}" and "\texttt{World}" included in a netstring acting as a container get encoded to "\texttt{16:5:Hello,5:World,,}". Keep in mind that the double comma after "\texttt{World}" is necessary, as one comma acts as the end-of-content symbol for the inner netstring and the last comma acts as the end-of-content symbol for the outer netstring which acts as the container. In this example, the nesting depth of 1 needed to be known beforehand. A nesting depth of 0 would signal that this structure represents one netstring of size 16 including the string "\texttt{5:Hello,5:world,}". Using the original specifications by D.J. Bernstein \cite{netstrings}, there exists no type-field in netstrings. Therefore, with these original specifications, the depth of nesting needs to be predetermined before parsing. A 'Heartbleed' package encoded as a netstring with payload $M=\texttt{"payload"}$ and padding \texttt{"padding"} would be "\texttt{17:7:payload,padding,}" with a nesting depth of 1. A malformed package used for the 'Heartbleed' attack could be "\texttt{6:9999:,,}".\\\\
Fixed nesting in netstrings is rather unpractical since the information about nesting depth has to be encoded and parsed separately before parsing the netstring itself. Therefore, we extended the definition for netstring slightly, so that variable nesting can be allowed. This means that the parser does not need to know any information about the nesting depth beforehand. As netstrings can act as either a simple netstring or as a container of other netstrings or containers, we can signal the parser at the start of every length-prefix which role this specific netstring will take. By prepending a zero (\texttt{0}) before the length-prefix, we mark this netstring as a container. We only allow the appearance of at most one leading zero in the length-prefix. A netstring with a nesting depth of 2 could look like "\texttt{012:08:5:Hello,,,}". The parser can parse this netstring without any prior knowledge of its nesting depth and still knows that this specific netstring represents a simple netstring of length 5 embedded in a container of size 8 which is then also embedded in another container of size 12.\\\\
While in Grosch et al.'s paper about Calc-Regular languages \cite{Calc-regular-paper} a solution to the handling of length-prefix languages with fixed nesting was proposed, this thesis will be focused on the challenges of a secure definition of length-prefix languages employing variable nesting.
\subsection{Google Protocol Buffers (Protobufs)}
\label{1.5}
Google protocol buffers are a language and platform neutral data serialization format for use in communication protocols or data storage amongst other things \cite{google-protobuf-overview}. Protobufs are a prime example for a variably nested length-prefix language widely used in practice. Contrary to netstrings, protobuf is a schema-language and additionally includes a type-field which conveys information also related to the current schema it is based on \cite{google-protobuf-encoding}. This language also does not use any delimiters or end-of-content symbols and encodes type field, length field and content field in immediate sequence.\\\\
To give a brief example, the strings "Hello" and "World" in two sequential protobufs are encoded in hexadecimal ASCII representation to "\texttt{12 05 48 65 6C 6C 6F 0A 05 57 6F 72 6C 64}". The first byte (\texttt{12}) and the eighth byte (\texttt{0A}) represent the type-fields of the corresponding string encodings. Second (\texttt{05}) and ninth (\texttt{05}) byte represent the length-fields containing the length of the upcoming string, which are the next five bytes respectively. It is important to mention one of the major differences to netstrings: encoded in a stream with several messages followed by another, the type-field byte of the upcoming message comes immediately after the last byte of the content-field from the prior message encoding. Netstrings (and many other length-prefix languages), on the other hand, employ an extra end-of-content symbol.
